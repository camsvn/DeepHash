{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training using Triplet loss.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GOWnJuCBno7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/jjmachan/DeepHash.git\n",
        "import DeepHash.datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M62tQcAHntn2",
        "colab_type": "text"
      },
      "source": [
        "# Training Using the Triplet Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9u5OIoawwId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import numpy as np\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.optim as optim\n",
        "\n",
        "from DeepHash.trainer import fit\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from DeepHash.utils import freeze_model, list_trainable, del_last_layers, save, load, create_embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD93VGcow0WB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "num_workers = 1\n",
        "\n",
        "#define transforms\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# load imagenet\n",
        "image_dataset = {\n",
        "        'train' :datasets.CIFAR10('./', train=True, download=True, transform=data_transforms['train']),\n",
        "        'test' : datasets.CIFAR10('./', train=False, download=True, transform=data_transforms['train']) \n",
        "}\n",
        "\n",
        "# Create the dataloaders\n",
        "data_loader = {\n",
        "    'train': torch.utils.data.DataLoader(image_dataset['train'], batch_size=batch_size, shuffle=True, num_workers=num_workers),\n",
        "    'test': torch.utils.data.DataLoader(image_dataset['test'], batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j7_JBDlw6zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# An identity layer to pass the fc layer in resnet\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x\n",
        "  \n",
        "# Define model\n",
        "resnet18  = models.resnet18(pretrained=True)\n",
        "resnet18.fc = Identity()\n",
        "\n",
        "# Freeze all the parameters in the model\n",
        "def freeze_model(model):\n",
        "  for params in model.parameters():\n",
        "    params.requires_grad=False\n",
        "\n",
        "# freeze\n",
        "#freeze_model(vgg19)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnvccdqb6c0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(triplet_train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(images[0].shape)\n",
        "# show images\n",
        "imshow(images[0][0])\n",
        "# print labels\n",
        "#print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xnXFaWMlxnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up data loaders\n",
        "from DeepHash.datasets import TripletCifar1\n",
        "from triplet.datasets import TripletMNIST\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "triplet_train_dataset = TripletCifar1(image_dataset['train']) # Returns triplets of images\n",
        "triplet_test_dataset = TripletCifar1(image_dataset['test'])\n",
        "batch_size = 32\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
        "triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
        "triplet_test_loader = torch.utils.data.DataLoader(triplet_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
        "\n",
        "# Set up the network and training parameters\n",
        "from triplet.networks import EmbeddingNet, TripletNet\n",
        "from triplet.losses import TripletLoss\n",
        "\n",
        "margin = 2.\n",
        "embedding_net = resnet18\n",
        "model = TripletNet(embedding_net)\n",
        "if cuda:\n",
        "    model.cuda()\n",
        "loss_fn = TripletLoss(margin)\n",
        "lr = 1e-3\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
        "n_epochs = 10\n",
        "log_interval = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUkHpGiVl1JX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit(triplet_train_loader, triplet_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzxfPC3avk-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model, './triplet_resnet18_2.mdl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtqvO2WPKUnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit(triplet_train_loader, triplet_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD21WqXCHlqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model, './triplet_vgg20_3.mdl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddYXN5naIdXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kodDsXoMwF6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save to google drive \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "!cp *.mdl /gdrive/My\\ Drive/tooploox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP3tTynrwS_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "!cp /gdrive/My\\ Drive/tooploox/*.mdl ./ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj5dM0U2v4f9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_test = torch.load('./triplet_resnet18_2.mdl')\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOw-fCVY_sGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze all the parameters in the model\n",
        "def freeze_model(model):\n",
        "  for params in model.parameters():\n",
        "    params.requires_grad=False\n",
        "\n",
        "# check if all the parameters have been freezed\n",
        "def list_trainable(model):\n",
        "  for params in model.parameters():\n",
        "    print(params.requires_grad)\n",
        "  \n",
        "# delete the last layers\n",
        "def del_last_layers(model_class, num_layers):\n",
        "  model_class = nn.Sequential(*list(model_class.children())[:-num_layers])\n",
        "  return model_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6-64Pswx7GH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_embeddings(model, embedding_size):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  print(device)\n",
        "\n",
        "  features = {}\n",
        "  targets = {}\n",
        "  model.to(device)\n",
        "  features['train'] = np.empty([0, embedding_size])\n",
        "  targets['train'] = np.empty([0, ])\n",
        "\n",
        "  features['test'] = np.empty([0, embedding_size])\n",
        "  targets['test'] = np.empty([0,])\n",
        "\n",
        "  for i, (images,target) in enumerate(data_loader['train']):\n",
        "    images = images.to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    try:\n",
        "      output = model(images).cpu().numpy()\n",
        "      features['train'] = np.append(features['train'],output, axis=0)\n",
        "      targets['train'] = np.append(targets['train'],target.cpu(), axis=0)\n",
        "    except:\n",
        "      print(output.shape)\n",
        "      print('error occured: ')\n",
        "      return (None, None)\n",
        "      \n",
        "    if i%100 == 0:\n",
        "      print(i)\n",
        "\n",
        "  for i, (images,target) in enumerate(data_loader['test']):\n",
        "    images = images.to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    output = model(images).cpu().numpy()\n",
        "    features['test'] = np.append(features['test'],output, axis=0)\n",
        "    targets['test'] = np.append(targets['test'],target.cpu(), axis=0)\n",
        "\n",
        "    if i%100 == 0:\n",
        "      print(i)\n",
        "  return (features, targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGjNaMPZyvWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_emb = model.embedding_net\n",
        "freeze_model(model_emb)\n",
        "print(model_emb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8_GyOjMylBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from DeepHash.utils import create_embeddings\n",
        "features, targets = create_embeddings(model_emb, data_loader, 512)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Miqi61eqAIvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the computed embeddings\n",
        "save(features, targets, 'resnet18_triplet_margin2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6waqp5oATjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save to google drive \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "!cp *.embs /gdrive/My\\ Drive/tooploox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAUnLJeCZlaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /gdrive/My\\ Drive/tooploox/*.embs ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP891c-sYuQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /gdrive/My\\ Drive/tooploox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMi42EReZye9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features, target = load('resnet18_triplet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQL8T6YEkhS_",
        "colab_type": "text"
      },
      "source": [
        "# Classification Accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpDtuaMfAUms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "k_range = range(25,30)\n",
        "\n",
        "def search_knn_accuracies(k_range, features, targets):\n",
        "  acc = []\n",
        "  for k in k_range:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(features['train'], targets['train'])\n",
        "    #print('finished fitting')\n",
        "    predict = knn.predict(features['test'][:300,:])\n",
        "    #print('predicted')\n",
        "    score = metrics.accuracy_score(targets['test'][:300], predict)\n",
        "    print('K value: %d, accuracy: %0.7f' %(k, score))\n",
        "    acc.append(score)\n",
        "  return acc\n",
        "\n",
        "\n",
        "# the best score was obtained when k = 20:24\n",
        "acc = search_knn_accuracies(k_range, features, target)\n",
        "print('final Accuracy: ',sum(acc)/len(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeQqnXTikqxO",
        "colab_type": "text"
      },
      "source": [
        "# t-SNE plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFy1JSKSAZU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as PathEffects\n",
        "from sklearn.manifold import TSNE\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "sns.set_palette('muted')\n",
        "sns.set_context(\"notebook\", font_scale=1.5,\n",
        "                rc={\"lines.linewidth\": 2.5})\n",
        "RS = 123\n",
        "# need to create a subset of the data, too much time to process otherwise\n",
        "x_subset = features['train'][:2000]\n",
        "y_subset = targets['train'][:2000]\n",
        "\n",
        "print(np.unique(y_subset))\n",
        "labels = {\n",
        "     0: 'airplane',  \n",
        "     1: 'automobile',\n",
        "     2: 'bird',\n",
        "     3: 'cat',\n",
        "     4: 'deer',\n",
        "     5: 'dog',\n",
        "     6: 'frog',\n",
        "     7: 'horse',\n",
        "     8: 'ship',\n",
        "     9: 'truck',\n",
        "}\n",
        "# Utility function to visualize the outputs of PCA and t-SNE\n",
        "\n",
        "def fashion_scatter(x, colors):\n",
        "    # choose a color palette with seaborn.\n",
        "    num_classes = len(np.unique(colors))\n",
        "    palette = np.array(sns.color_palette(\"hls\", num_classes))\n",
        "\n",
        "    # create a scatter plot.\n",
        "    f = plt.figure(figsize=(8, 8))\n",
        "    ax = plt.subplot(aspect='equal')\n",
        "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40, c=palette[colors.astype(np.int)])\n",
        "    plt.xlim(-25, 25)\n",
        "    plt.ylim(-25, 25)\n",
        "    ax.axis('off')\n",
        "    ax.axis('tight')\n",
        "\n",
        "    # add the labels for each digit corresponding to the label\n",
        "    txts = []\n",
        "\n",
        "    for i in range(num_classes):\n",
        "\n",
        "        # Position of each label at median of data points.\n",
        "\n",
        "        xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
        "        txt = ax.text(xtext, ytext, str(labels[i]), fontsize=24)\n",
        "        txt.set_path_effects([\n",
        "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
        "            PathEffects.Normal()])\n",
        "        txts.append(txt)\n",
        "\n",
        "    return f, ax, sc, txts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD-BsELyA6BR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# do pca before passing to tsne to reduce noice and fast performance\n",
        "time_start = time.time()\n",
        "\n",
        "pca_50 = PCA(n_components=50)\n",
        "pca_result_50 = pca_50.fit_transform(x_subset)\n",
        "\n",
        "print('PCA with 50 components done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
        "\n",
        "print('Cumulative variance explained by 50 principal components: {}'.format(np.sum(pca_50.explained_variance_ratio_)))\n",
        "# perform tsne on 50 components\n",
        "time_start = time.time()\n",
        "\n",
        "\n",
        "fashion_pca_tsne = TSNE(random_state=RS).fit_transform(pca_result_50)\n",
        "\n",
        "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2HvhLmEA-ah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_scatter(fashion_pca_tsne, y_subset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqfk3460dGYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3T9eTgFHje3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one = features['train'][0].reshape(1,-1)\n",
        "one_label = target['train'][0]\n",
        "print(one_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y-f4Ss-an3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.linalg.norm(features['test']-one, axis=1)\n",
        "a.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhTHY4xtat89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_a = np.append(a.reshape(-1,1), target['test'].reshape(-1,1), axis=1)\n",
        "new_a = new_a.tolist()\n",
        "new_a[:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EOcRCXJazOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def take_fist(elem):\n",
        "  return elem[0]\n",
        "\n",
        "sorted_a = sorted(new_a, key=take_fist)\n",
        "sorted_a = np.array(sorted_a)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2rT2fYJa51f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_label_map = target['test'] == one_label\n",
        "sorted_a = one_label_map*sorted_a[:,0]\n",
        "sorted_a[:90]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT5nU9SBa80D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, num in enumerate(sorted_a):\n",
        "  print(i, num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9tfzTz-bFoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}